# ğŸš€ Data Engineering Complete - ML Team Handoff

**Date:** November 4, 2025  
**From:** Data Engineer (Member 1)  
**To:** ML Engineer (Member 2)  
**Status:** âœ… ALL DELIVERABLES READY

---

## ğŸ“‹ Executive Summary

All data engineering work for the **AI-Powered Fault Prediction in 5G Testbed** project is complete. The synthetic dataset has been generated, preprocessed, analyzed, and is ready for model training.

---

## ğŸ“¦ Deliverables

### 1. **Datasets** (Location: `data/`)

| File | Samples | Features | Size | Purpose |
|------|---------|----------|------|---------|
| `synthetic_5g_fault_dataset.csv` | 10,000 | 19 | 1.29 MB | Original raw data |
| `train.csv` | 8,000 | 18 | 2.31 MB | Training set (preprocessed) |
| `test.csv` | 2,000 | 18 | 0.58 MB | Testing set (preprocessed) |
| `scaler.pkl` | - | - | - | StandardScaler for deployment |
| `label_encoder.pkl` | - | - | - | LabelEncoder for deployment |

**Class Distribution:**
- Training: 70.6% Faulty, 29.4% Normal
- Testing: 70.7% Faulty, 29.3% Normal
- âœ… Stratified split maintains balance

---

## ğŸ¯ Key Features (18 Total)

### Network Quality Metrics (6 features)
1. **rssi_dbm** - Received Signal Strength Indicator (-120 to -50 dBm)
2. **sinr_db** - Signal-to-Interference-plus-Noise Ratio (-5 to 30 dB)
3. **throughput_mbps** - Network throughput (10 to 150 Mbps)
4. **latency_ms** - Network latency (1 to 300 ms)
5. **jitter_ms** - Network jitter (1 to 50 ms)
6. **packet_loss_percent** - Packet loss rate (0 to 30%)

### Infrastructure Metrics (4 features)
7. **cpu_usage_percent** - CPU utilization (20 to 100%)
8. **memory_usage_percent** - Memory utilization (30 to 100%)
9. **active_users** - Concurrent users (50 to 1000)
10. **temperature_celsius** - Device temperature (25 to 90Â°C)

### Temporal Features (3 features)
11. **hour** - Hour of day (0-23)
12. **day_of_week** - Day of week (0-6)
13. **is_peak_hour** - Peak hour indicator (0 or 1)

### Derived Features (2 features)
14. **network_quality_score** - Composite quality metric (0-1)
15. **resource_stress** - Infrastructure stress indicator (0-1)

### Identifiers (3 features - encoded)
16. **base_station_id** - Base station identifier (encoded)
17. **cell_id** - Cell identifier (encoded)
18. **target** - Fault status (0=Faulty, 1=Normal)

---

## ğŸ” EDA Insights (from `notebooks/eda_report.ipynb`)

### Top Predictive Features (Correlation with Target)
1. **network_quality_score**: -0.98 â­ *Strongest predictor*
2. **jitter_ms**: 0.95
3. **rssi_dbm**: -0.95
4. **latency_ms**: 0.93
5. **sinr_db**: -0.93
6. **throughput_mbps**: -0.92
7. **packet_loss_percent**: 0.91
8. **active_users**: 0.85
9. **temperature_celsius**: 0.82
10. **resource_stress**: 0.51

### Feature Correlations to Watch
- **RSSI â†” SINR**: r = 0.88 (expected correlation)
- **Latency â†” Jitter**: r = 0.89 (strongly correlated)
- **Throughput â†” RSSI**: r = 0.87
- **Active Users â†” Temperature**: r = 0.70

**âš ï¸ Recommendation:** Consider feature selection to reduce multicollinearity

### Distribution Characteristics
- **Faulty vs Normal differences:**
  - Latency: 142.58 ms average difference
  - Throughput: 90.71 Mbps difference
  - RSSI: 42.13 dBm difference
  - SINR: 22.52 dB difference

- **Temporal patterns:** Fault rate consistent at ~29.4% across all times

---

## ğŸ¤– ML Model Recommendations

### Suggested Algorithms
1. **Random Forest Classifier** â­ *Recommended*
   - Handles non-linearity well
   - Resistant to overfitting
   - Provides feature importance
   - Good baseline model

2. **XGBoost Classifier** â­ *Recommended*
   - Excellent for tabular data
   - Handles class imbalance
   - Fast training and inference
   - High accuracy potential

3. **Neural Network (MLP)**
   - Can capture complex patterns
   - Good for large datasets
   - Requires more tuning

4. **Ensemble Methods**
   - Combine multiple models
   - Voting or stacking
   - Best overall performance

### Hyperparameter Tuning Strategy
- Use **GridSearchCV** or **RandomizedSearchCV**
- Apply **5-fold Stratified Cross-Validation**
- Optimize for **F1-Score** or **Recall**

---

## ğŸ“Š Evaluation Metrics Priority

### Primary Metrics
1. **Recall (Sensitivity)** - *Most Important*
   - Goal: Detect ALL faults (minimize false negatives)
   - Critical for 5G network reliability

2. **Precision**
   - Goal: Minimize false alarms
   - Balance with Recall

3. **F1-Score**
   - Harmonic mean of Precision and Recall
   - Good overall metric

### Secondary Metrics
4. **ROC-AUC Score** - Model discrimination ability
5. **Confusion Matrix** - Detailed error analysis
6. **Classification Report** - Per-class performance

### Target Performance
- **Minimum Recall:** 95% (catch 95% of faults)
- **Minimum Precision:** 85% (limit false alarms)
- **Target F1-Score:** 90%+

---

## ğŸ”§ Preprocessing Pipeline (Already Applied)

### What's Done
âœ… **Missing Values:** None (clean dataset)  
âœ… **Duplicates:** Removed  
âœ… **Scaling:** StandardScaler on 15 numeric features  
âœ… **Encoding:** LabelEncoder on categorical and target  
âœ… **Train-Test Split:** 80-20 stratified split  
âœ… **Artifacts Saved:** scaler.pkl, label_encoder.pkl for deployment

### What You Need to Do
1. Load `train.csv` and `test.csv`
2. Separate features (X) and target (y)
3. Train your model on training set
4. Evaluate on test set
5. Save trained model (e.g., `model.pkl`)

---

## ğŸ’» Sample Training Code

```python
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score
import pickle

# Load preprocessed data
train_df = pd.read_csv('../data/train.csv')
test_df = pd.read_csv('../data/test.csv')

# Separate features and target
X_train = train_df.drop('target', axis=1)
y_train = train_df['target']
X_test = test_df.drop('target', axis=1)
y_test = test_df['target']

# Train Random Forest
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=15,
    min_samples_split=10,
    class_weight='balanced',
    random_state=42,
    n_jobs=-1
)

rf_model.fit(X_train, y_train)

# Predictions
y_pred = rf_model.predict(X_test)
y_pred_proba = rf_model.predict_proba(X_test)[:, 1]

# Evaluation
print("Classification Report:")
print(classification_report(y_test, y_pred, target_names=['Faulty', 'Normal']))

print("\nConfusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print(f"\nROC-AUC Score: {roc_auc_score(y_test, y_pred_proba):.4f}")

# Save model
with open('../models/random_forest_model.pkl', 'wb') as f:
    pickle.dump(rf_model, f)

print("\nâœ… Model saved to models/random_forest_model.pkl")
```

---

## ğŸ“ File Locations

```
AI-powered-fault-prediction/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ synthetic_5g_fault_dataset.csv  # Original data
â”‚   â”œâ”€â”€ train.csv                        # Training set â­
â”‚   â”œâ”€â”€ test.csv                         # Testing set â­
â”‚   â”œâ”€â”€ scaler.pkl                       # For deployment â­
â”‚   â”œâ”€â”€ label_encoder.pkl                # For deployment â­
â”‚   â””â”€â”€ data_documentation.md            # Feature descriptions
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ eda_report.ipynb                 # Full EDA with visualizations â­
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_synthetic_data.py       # Data generation script
â”‚   â””â”€â”€ data_preprocessing.py            # Preprocessing pipeline
â”œâ”€â”€ models/                              # Save your models here â­
â”œâ”€â”€ README.md                            # Project overview
â””â”€â”€ requirements.txt                     # Dependencies
```

---

## ğŸš¨ Important Notes

### Class Imbalance Handling
- Dataset has 2.4:1 Normal-to-Faulty ratio
- **Use `class_weight='balanced'`** in sklearn models
- Or apply **SMOTE** for oversampling
- Or **RandomUnderSampler** for undersampling

### Feature Engineering Ideas
- Interaction terms (e.g., RSSI Ã— SINR)
- Polynomial features
- Time-based aggregations
- Moving averages

### Overfitting Prevention
- Use cross-validation
- Apply regularization (L1/L2)
- Limit tree depth (for tree-based models)
- Use dropout (for neural networks)
- Monitor validation loss

### Deployment Considerations
- **Always use saved scaler.pkl** for new predictions
- **Always use saved label_encoder.pkl** for target decoding
- Model should accept 17 features (18 columns minus target)
- Return predictions as "Faulty" or "Normal" (decoded)

---

## âœ… Quality Checks Passed

- [x] No missing values
- [x] No duplicate records
- [x] All features within valid ranges
- [x] Class distribution maintained in train/test split
- [x] Scaling applied correctly
- [x] Encoding applied correctly
- [x] Artifacts saved for deployment
- [x] EDA completed with insights
- [x] Documentation created

---

## ğŸ“ Next Steps for ML Team

1. **Review EDA notebook** (`notebooks/eda_report.ipynb`)
2. **Load training and testing data** (`data/train.csv`, `data/test.csv`)
3. **Train baseline models** (Random Forest, XGBoost)
4. **Hyperparameter tuning** using cross-validation
5. **Evaluate models** on test set
6. **Select best model** based on Recall and F1-Score
7. **Save final model** to `models/` directory
8. **Document model performance** for Backend Team

---

## ğŸ¤ Backend Team Integration Notes

### API Requirements
- Load `scaler.pkl` and `label_encoder.pkl` at startup
- Load trained model (e.g., `model.pkl`)
- Accept 17 input features (all except target)
- Scale inputs using loaded scaler
- Return prediction: "Faulty" or "Normal"
- Include prediction probability/confidence

### Example API Input Format
```json
{
  "rssi_dbm": -85.5,
  "sinr_db": 12.3,
  "throughput_mbps": 95.7,
  "latency_ms": 25.4,
  "jitter_ms": 5.2,
  "packet_loss_percent": 1.8,
  "cpu_usage_percent": 65.3,
  "memory_usage_percent": 58.7,
  "active_users": 450,
  "temperature_celsius": 55.2,
  "hour": 14,
  "day_of_week": 2,
  "is_peak_hour": 1,
  "network_quality_score": 0.75,
  "resource_stress": 0.42,
  "base_station_id": 5,
  "cell_id": 12
}
```

### Example API Output Format
```json
{
  "prediction": "Normal",
  "confidence": 0.87,
  "probability_faulty": 0.13,
  "probability_normal": 0.87,
  "timestamp": "2025-11-04T14:30:00Z"
}
```

---

## ğŸ“š Additional Resources

- **Feature Documentation:** `data/data_documentation.md`
- **EDA Notebook:** `notebooks/eda_report.ipynb`
- **Project README:** `README.md`
- **Requirements:** `requirements.txt`

---

## âœ¨ Data Engineering Summary

### Days 1-4 Completed
- âœ… **Day 1:** Synthetic dataset generation (10,000 samples)
- âœ… **Day 2:** Data preprocessing pipeline (train/test split)
- âœ… **Day 3:** Exploratory data analysis (insights & visualizations)
- âœ… **Day 4:** Final documentation and team handoff

### Dataset Quality
- **Comprehensive:** 19 features covering network, infrastructure, temporal, and derived metrics
- **Realistic:** Based on actual 5G network parameter ranges
- **Clean:** No missing values, no duplicates, no outliers outside valid ranges
- **Balanced:** Acceptable class distribution for training
- **Ready:** Fully preprocessed and deployment-ready

---

**ğŸ¯ You're all set! Happy model training! ğŸš€**

For questions, refer to the documentation or reach out to the Data Engineering team.

---

*Document Version: 1.0*  
*Last Updated: November 4, 2025*  
*Author: Data Engineer (Member 1)*
